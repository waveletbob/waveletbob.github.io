---
layout: post
title: Python数据科学核心库
categories: 数据科学 
tags: 数据科学 Python

---
## Python数据科学库 ##

## <center>核心库</center> ##

#### 1）Numpy ####

当使用 Python 开始处理科学任务时，不可避免地需要求助 Python 的 SciPy Stack，它是专门为 Python 中的科学计算而设计的软件的集合（不要与 SciPy 混淆，它只是这个 stack 的一部分，以及围绕这个 stack 的社区）。
这个 stack 相当庞大，其中有十几个。NumPy（代表 Numerical Python）是构建科学计算 stack 的最基础的包。它为 Python 中的 n 维数组和矩阵的操作提供了大量有用的功能。该库还提供了 NumPy 数组类型的数学运算向量化，可以提升性能，从而加快执行速度。
#### 2）Scipy ####

SciPy 包含线性代数、优化、集成和统计的模块。SciPy 库的主要功能建立在 NumPy 的基础之上，因此它的数组大量使用了 NumPy。它通过其特定的子模块提供高效的数值例程操作，比如数值积分、优化和许多其他例程。SciPy 的所有子模块中的函数都有详细的文档，这也是一个优势。
#### 3）Pandas ####

Pandas 是一个 Python 包，旨在通过「标记（labeled）」和「关系（relational）」数据进行工作，简单直观。Pandas 是 data wrangling 的完美工具。它设计用于快速简单的数据操作、聚合和可视化。库中有两个主要的数据结构：Series（一维）、Data Frames（二维）
## <center>可视化</center> ##

#### 4）Matplotlib ####

利用它可以创建标签、网格、图例和许多其他格式化实体的功能

- 线图
- 散点图
- 条形图和直方图
- 饼状图
- 茎图
- 轮廓图
- 场图
- 频谱图

#### 5）Seaborn ####

Seaborn 主要关注统计模型的可视化；这种可视化包括热度图（heat map），可以总结数据但也描绘总体分布。

#### 6）Bokeh ####

其目的是交互式可视化

#### 7）Plotly ####

它是一个基于 Web 的工具箱，用于构建可视化，将 API 呈现给某些编程语言（其中包括 Python）

## <center>机器学习</center> ##

#### 8）Scikit-Learn ####

该软件包构建于 SciPy 之上，并大量使用其数学操作。

#### 9）Theano ####

Theano 是一个 Python 包，它定义了与 NumPy 类似的多维数组，以及数学运算和表达式。该库是经过编译的，使其在所有架构上能够高效运行。这个库最初由蒙特利尔大学机器学习组开发，主要是为了满足机器学习的需求。

要注意的是，Theano 与 NumPy 在底层的操作上紧密集成。该库还优化了 GPU 和 CPU 的使用，使数据密集型计算的性能更快。

效率和稳定性调整允许更精确的结果，即使是非常小的值也可以，例如，即使 x 很小，log(1+x) 也能得到很好的结果。

#### 10）Keras ####

它可以在 TensorFlow 或者 Theano 之上运行。使用 Theano 或 TensorFlow 作为后端，但 Microsoft 现在已将 CNTK（Microsoft 的认知工具包）集成为新的后端。

#### 11）Tensorflow ####

TensorFlow 来自 Google 的开发人员，它是用于数据流图计算的开源库，专门为机器学习设计。它是为满足 Google 对训练神经网络的高要求而设计的，是基于神经网络的机器学习系统 DistBelief 的继任者。然而，TensorFlow 并不是谷歌的科学专用的——它也足以支持许多真实世界的应用。

TensorFlow 的关键特征是其多层节点系统，可以在大型数据集上快速训练人工神经网络。这为 Google 的语音识别和图像识别提供了支持。
## <center>NLP</center> ##

#### 12）NLTK ####

这套库的名称是 Natural Language Toolkit（自然语言工具包），顾名思义，它可用于符号和统计自然语言处理的常见任务。NLTK 旨在促进 NLP 及相关领域（语言学、认知科学和人工智能等）的教学和研究，目前正被重点关注。

NLTK 允许许多操作，例如文本标记、分类和 tokenizing、命名实体识别、建立语语料库树（揭示句子间和句子内的依存性）、词干提取、语义推理。所有的构建块都可以为不同的任务构建复杂的研究系统，例如情绪分析、自动摘要。

#### 13）Gensim ####

实现了用于向量空间建模和主题建模的工具。这个库为大文本进行了有效的设计，而不仅仅可以处理内存中内容。其通过广泛使用 NumPy 数据结构和 SciPy 操作而实现了效率。它既高效又易于使用。

Gensim 的目标是可以应用原始的和非结构化的数字文本。Gensim 实现了诸如分层 Dirichlet 进程（HDP）、潜在语义分析（LSA）和潜在 Dirichlet 分配（LDA）等算法，还有 tf-idf、随机投影、word2vec 和 document2vec，以便于检查一组文档（通常称为语料库）中文本的重复模式。所有这些算法是无监督的——不需要任何参数，唯一的输入是语料库。

## <center>数据挖掘与统计</center> ##

#### 14）Scrapy ####

用于从网络检索结构化数据（如联系人信息或 URL）的爬虫程序（也称为 spider bots）的库。

#### 15）Statsmodels ####

其让用户能够通过使用各种统计模型估计方法以及执行统计断言和分析来进行数据探索。

许多有用的特征是描述性的，并可通过使用线性回归模型、广义线性模型、离散选择模型、稳健的线性模型、时序分析模型、各种估计器进行统计。

该库还提供了广泛的绘图函数，专门用于统计分析和调整使用大数据统计数据的良好性能。