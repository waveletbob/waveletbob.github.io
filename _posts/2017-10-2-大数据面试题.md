---
layout: post
title: 大数据面试题
categories: 数据科学
tags: 大数据

---

### 1）Hadoop ###

- hadoop历史
- hadoop优劣
- hadoop mapreduce过程
	- map
	- shuffle
		- partition
		- sort
		- combiner（本地reduce，实现本地key聚合排序，value迭代）
	- reduce
- hadoop进程角色
- 1.x和2.x区别
- shuffle优化
- 输入输出数据格式
- common、core、client的区别
	- common由core改名而来，用来集成Hadoop相关模块的
	- core低版本的核心库，现在被common取代
	- client用来构建hadoop app，通常用户有这个就可以使用hdfs、YARN、MR job
- Hadoop的HA实现
 
- Hadoop数据备份与数据存储HDFS
- 多job并行处理优化 
- hadoop2.0组成
	- HDFS、YARN、MR与其他计算框架（1.0基础上加入YARN）
	- 解决单点故障HA与内存受限HDFS Federation（多namenode，分管部分目录）
- job提交的过程（RM申请资源，注册任务，）
	- Clinet提交job，RPC和RM
	- RM返回资源路径与jobid
	- Client提交资源
	- 向RM汇报资源提交结果
	- RM将job放入任务队列
	- NodeManager从RM中领任务
	- RM在NM中分配Container资源容器
	- RM找到DN启动MRAppMaster管理进程
	- DN的MRAppMaster向RM注册
	- MRAppMaster启动Map
	- MRAppMaster启动Reduce
	- 任务完成，MRAppMaster向RM注销

- Hadoop生态圈以及各使用场景（Hive、Hbase、Pig、Mahout、Zookeeper等）
- Hadoop 压缩
- Hadoop小文件合并
- 找出重复出现最多的前10条信息（一个哈希表，统计次数，同时维护一张长度为10的短信表）
- 数据如何导入到数据库（先上传到hdfs，然后hive数据仓库处理，最后用sqoop导出到mysql供报表）
- 一般处理数据将日志数据导入到hdfs之后进行处理
- hive与hbase的区别--数据仓库（统计查询类SQL引擎）、数据库（实时查询）
- 项目中遇到哪些问题
- hdfs复制时宕机怎么保证下次还是复制这个副本
- block信息先写DN还是先写NN
- HA启动顺序：Zookeeper->Hadoop->Hbase
- Block块大小（64MB、128MB）、默认多少份？
- Hadoop开发用到的算法以及应用场景？
排序、分组、topk、join、group
- HA 时Cofiguration配置
有三种：jar包（默认配置）、site级别（集群安装配置），这两种都是classpath加载，最后是用户代码设置的参数
故障自动转移（zookeeper）配置、ResourceManager HA
- 


### 2）Spark ###
- spark streaming与Storm对比
	- 准实时（秒级）<实时（金融毫秒级）
	- 吞吐量（高）>低
	- 事务机制 < 完善
	- 健壮性（鲁棒性）、容错性<
	- 动态调整并行度(不支持)<支持
	- 与其他系统整合>扩展性
	- 实时性要求不高的场景、事务机制不要求强大、不要求动态调整并行度可以考虑用Spark Streaming，否则还是用Storm


### 3）Hbase ###
- 存什么数据
- rowkey	
	- 长度原则
	- 散列原则
	- 唯一原则
	- 热点
	- 避免热点
		- 加盐
		- 哈希
		- 反转
		- 时间戳反转
	
- column key（column family and qualifier）、timestamp
- hbase如何预分区
hbase建表时默认有个region，这个region的rowkey是没有边界的，初始数据写入此region，随着数据量增大，需要split，会产生两个问题：写热点、split会消耗集群IO资源，为解决这个问题，预先创建多个空分区，确定每个region的起始和终止rowkey。

要进行预分区，首先要明确rowkey的取值范围或构成逻辑，以rowkey组成为例:两位随机数+时间戳+客户号，两位随机数的范围从00-99，于是我划分了10个region来存储数据,每个region对应的rowkey范围如下：-10,10-20,20-30,30-40,40-50,50-60,60-70,70-80,80-90,90-

- hbase如何提供web前台接口访问
- htable API线性安全问题，程序中单例还是多例
单例没问题，并发多线程就出问题了
- hbase并发问题
- Hbase读写性能优化
	- 开启布隆过滤器
	- 划分更多内存
	- 替换默认的JVM垃圾回收器
	- 增大RPC数量
	- 用HTable.exists(final byte [] row, final byte[]column)等带列族的方法判断数据行是否存在
	- 预拆分region


### 4）Kafka ###


### 5）Hive ###
- 处理数据能达到的指标
- 压缩格式
	- TextFile（加载速度最快，压缩后的文件无法split）
	- SequenceFile（压缩率最低，查询速度一般）
	- RCFile（行块、块列存、速度快、压缩率高、数据加载慢）
	- ORCFile（最好）
- udf函数怎么写
### 6）Redis ###

### 7)Storm ###

### 8）Flume ###

### 9）Zookeeper ###

### 10）YARN ###
- 运行流程

以前的资源管理和任务调度都在MR中，2中将资源管理与任务调度放在YARN中分别由ResourceManager（资源管理）和ApplicationMaster（任务调度、任务监控、任务容错）实现

（1）用户向YARN提交应用程序，包括ApplicationMaster程序，启动AM命令，用户程序；
（2）ResourceManager为应用程序分配container，并与之对应的NM通信，要求和container中启动应用程序对应的AM；
（3）AM启动后向RM注册；
（4）AM轮询提供RPC协议向RM申请资源
（5）申请到就与NM通信，启动任务；
（6）NM启动任务，并通过RPC向AM报告状态
（7）任务完成,AM向RM注销并关闭
- MR2.0与YARN的异同
	MR只是运行在YARN上的一个应用
- MRAppMaster作用，如何实现任务容错的
- 为什么会产生YARN，它是解决了什么问题，有什么优势？

MRv1存在大型集群下的级联故障以及多租户问题（需要不同的模型）

为实现Hadoop集群共享、可伸缩性、可靠性，设计了一种分层集群框架用来从特定MR框架功能转变为新的处理框架。

YARN:ResourceManager分配资源给基础NodeManager，还与ApplicationMaster一起分配资源，与NodeManager一起启动和监视基础应用程序，ApplicationMaster承担了TaskTracker的一些角色，而ResourceManager承担了JobTracker的角色。

ApplicationMaster：管理每个应用程序实例，协调来自NodeManager的资源；

NodeManager：管理每个节点的资源

总体来讲：YARN解决了扩展性差、单点故障、以及只能局限于MR框架的问题；

### 11）集群运维 ###

Ganglia